Act√∫a como Senior QA Engineer especializado en exploratory testing y session-based test management.

---

## üéØ TAREA

**FASE 10: TEST CHARTER GENERATION**

Crear charter de exploraci√≥n estructurado para sesi√≥n de testing manual que cubra funcionalidad completa de la story.

**Este prompt se ejecuta DESPU√âS de:**
- smoke-test.md pas√≥ exitosamente (deployment funcional)
- ANTES de session-notes.md (ejecuci√≥n de la sesi√≥n)

---

## üì• INPUT REQUERIDO

### 1. Story Actual

**Leer TODOS estos archivos:**
- `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/story.md` - **CR√çTICO** - Acceptance criteria completos
- `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/test-cases.md` - **CR√çTICO** - Test cases de Fase 5
- `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/smoke-test.md` - Resultado de smoke test

**Qu√© identificar:**
1. **Acceptance Criteria completos** - Qu√© debe funcionar
2. **Test cases definidos** - Happy path, edge cases, negative cases
3. **√Åreas de riesgo** - Funcionalidad compleja, integraciones, UX cr√≠tica

### 2. Deployment Context

**Leer:**
- `.context/infrastructure-setup.md` - URLs y configuraci√≥n
- `.context/SRS/design-specs.md` - Dise√±os y UX esperada (si aplica)

---

## ‚öôÔ∏è VERIFICACI√ìN DE HERRAMIENTAS (MCP)

**NO se requieren MCP para esta fase.**

### Herramientas Manuales:
- Browser para ejecutar testing
- DevTools (F12) para debugging
- Screenshot tools (opcional)

---

## üéØ OBJETIVO

Crear test charter que gu√≠a sesi√≥n exploratoria de 60-90 minutos:

**Incluye:**
- ‚úÖ √Åreas a explorar (basadas en ACs y test cases)
- ‚úÖ T√©cnicas de exploratory testing a usar
- ‚úÖ Time-boxing por √°rea (distribuci√≥n de tiempo)
- ‚úÖ Criterios de √©xito claros
- ‚úÖ Datos de prueba necesarios

**NO incluye:**
- ‚ùå Smoke test (ya ejecutado en prompt anterior)
- ‚ùå Tests automatizados (eso es Fase 11)
- ‚ùå Ejecuci√≥n de la sesi√≥n (eso es session-notes.md)

**Resultado:** Charter estructurado que QA ejecuta en **60-90 minutos** de exploratory testing.

---

## üì§ OUTPUT GENERADO

### Test Charter:
- ‚úÖ `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/test-charter.md` - Charter ejecutable

**Estructura del charter:**
```markdown
# Test Charter: [STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre} - Nombre]

**Fecha:** [Fecha]
**QA:** [Nombre]
**Duraci√≥n estimada:** 60-90 minutos
**Staging URL:** https://[project]-develop.vercel.app

---

## üéØ Objetivo de la Sesi√≥n

[Descripci√≥n de qu√© se va a explorar y por qu√©]

---

## üìã √Åreas a Explorar

### 1. [√Årea 1 - Happy Path]
- Qu√© probar: [Descripci√≥n]
- T√©cnica: Tours
- Tiempo: 15-20 minutos

### 2. [√Årea 2 - Edge Cases]
- Qu√© probar: [Descripci√≥n]
- T√©cnica: Boundary testing
- Tiempo: 20-25 minutos

### 3. [√Årea 3 - UX & Performance]
- Qu√© probar: [Descripci√≥n]
- T√©cnica: UX review
- Tiempo: 15-20 minutos

---

## üîç T√©cnicas a Usar

- [ ] Tours
- [ ] Edge cases
- [ ] Negative testing
- [ ] Pairing (diferentes user personas)
- [ ] UX review

---

## ‚úÖ Criterios de √âxito

- [ ] Happy path funciona end-to-end
- [ ] Validaciones claras
- [ ] No hay errores cr√≠ticos
- [ ] UX intuitiva

---

## üìù Datos de Prueba

[Credenciales, data seeds, etc.]
```

---

## üö® RESTRICCIONES CR√çTICAS

### ‚ùå NO HACER:

- **NO duplicar smoke test** - Smoke test ya valid√≥ happy path b√°sico
- **NO crear charter gen√©rico** - Debe ser espec√≠fico a la story
- **NO olvidar t√©cnicas de exploratory testing** - Tours, edge cases, negative testing
- **NO omitir time-boxing** - Cada √°rea debe tener tiempo estimado
- **NO incluir solo happy path** - Exploratory testing busca edge cases y bugs

### ‚úÖ S√ç HACER:

- **Basarse en test cases de Fase 5** - Usar test cases como gu√≠a
- **Time-box cada √°rea** - Distribuir 60-90 min efectivamente
- **Incluir diferentes t√©cnicas** - Tours, edge cases, pairing, negative testing
- **Especificar criterios de √©xito** - Qu√© debe funcionar para aprobar story
- **Incluir datos de prueba** - Credenciales, seeds, data necesaria

---

## üîÑ WORKFLOW

---

## üìã PASO 1: ANALIZAR STORY Y TEST CASES

**Objetivo:** Entender qu√© explorar.

### Paso 1.1: Leer Acceptance Criteria

**Acci√≥n:** Leer `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/story.md`

**Identificar:**
1. **ACs principales:**
   - AC1: [Descripci√≥n]
   - AC2: [Descripci√≥n]
   - AC3: [Descripci√≥n]

2. **Funcionalidad compleja:**
   - ¬øHay formularios con validaciones m√∫ltiples?
   - ¬øHay integraci√≥n con APIs externas?
   - ¬øHay l√≥gica de negocio compleja?

3. **√Åreas de riesgo:**
   - ¬øQu√© puede fallar?
   - ¬øQu√© es cr√≠tico para el usuario?

---

### Paso 1.2: Leer Test Cases de Fase 5

**Acci√≥n:** Leer `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/test-cases.md`

**Identificar:**
1. **Happy Path Test Cases:**
   - TC-001: [Descripci√≥n]
   - TC-002: [Descripci√≥n]

2. **Edge Cases Test Cases:**
   - TC-010: [Descripci√≥n]
   - TC-011: [Descripci√≥n]

3. **Negative Cases Test Cases:**
   - TC-020: [Descripci√≥n]
   - TC-021: [Descripci√≥n]

**Output al usuario:**
```markdown
## üìä An√°lisis Completado

### Acceptance Criteria a cubrir:
- AC1: [Descripci√≥n]
- AC2: [Descripci√≥n]
- AC3: [Descripci√≥n]

### Test Cases identificados:
- Happy path: [X] test cases
- Edge cases: [Y] test cases
- Negative cases: [Z] test cases

### √Åreas de riesgo:
- [√Årea 1 - ej: "Validaciones de formulario complejas"]
- [√Årea 2 - ej: "Integraci√≥n con API de pagos"]
```

---

## üó∫Ô∏è PASO 2: DIVIDIR EN √ÅREAS DE EXPLORACI√ìN

**Objetivo:** Estructurar sesi√≥n en √°reas time-boxed.

### Paso 2.1: Identificar √Åreas

**T√≠picamente 3-5 √°reas:**

**1. Happy Path (15-20 minutos):**
- Validar flujo principal end-to-end
- Ya cubierto en smoke test, pero explorar m√°s profundo
- T√©cnica: Tours

**2. Edge Cases (20-25 minutos):**
- Inputs l√≠mite, vac√≠os, inv√°lidos
- Boundary conditions
- T√©cnica: Boundary testing, Negative testing

**3. UX & Usabilidad (15-20 minutos):**
- ¬øUI es intuitiva?
- ¬øMensajes de error son claros?
- ¬øLoading states son apropiados?
- T√©cnica: UX review, User personas

**4. Integraci√≥n con Backend (15-20 minutos):**
- APIs funcionan correctamente
- Data persiste
- Error handling de backend
- T√©cnica: Data flows, API testing

**5. Performance & Responsiveness (10-15 minutos) - Opcional:**
- Load times aceptables
- Responsive design funciona
- T√©cnica: Performance profiling

---

### Paso 2.2: Time-boxing

**Total: 60-90 minutos**

**Distribuci√≥n recomendada:**
```
√Årea 1 (Happy Path):          15-20 min  (25%)
√Årea 2 (Edge Cases):           20-25 min  (35%)
√Årea 3 (UX):                   15-20 min  (25%)
√Årea 4 (Backend):              10-15 min  (15%)
Buffer para bugs encontrados:  10 min
```

**Ajustar seg√∫n complejidad de la story.**

---

## üõ†Ô∏è PASO 3: DEFINIR T√âCNICAS DE EXPLORATORY TESTING

**Objetivo:** Especificar c√≥mo explorar cada √°rea.

### T√©cnicas Disponibles:

**1. Tours (Guided exploration):**
- **Feature Tour:** Explorar todas las features de la story
- **User Tour:** Explorar desde perspectiva de user persona
- **Data Tour:** Explorar diferentes tipos de data

**2. Edge Cases & Boundary Testing:**
- Inputs l√≠mite (max length, min value, etc.)
- Inputs vac√≠os
- Inputs inv√°lidos (special characters, SQL injection attempts, XSS)
- Null/undefined values

**3. Negative Testing:**
- ¬øQu√© pasa si usuario hace algo incorrecto?
- ¬øValidaciones funcionan?
- ¬øMensajes de error son claros?

**4. Pairing (User Personas):**
- Probar como Admin vs User vs Guest
- Diferentes roles tienen diferentes permisos

**5. UX Review:**
- ¬øUI es intuitiva?
- ¬øNavegaci√≥n es clara?
- ¬øFeedback visual es apropiado?

**6. Performance Testing:**
- Load times
- Responsiveness
- Stress testing (muchos datos)

---

### Paso 3.1: Asignar T√©cnicas a √Åreas

**Mapeo:**

```markdown
| √Årea                | T√©cnicas                          |
|---------------------|-----------------------------------|
| Happy Path          | Tours, Feature Tour               |
| Edge Cases          | Boundary Testing, Negative Testing|
| UX                  | UX Review, Pairing                |
| Backend Integration | Data flows, API testing           |
| Performance         | Performance profiling             |
```

---

## üìù PASO 4: DEFINIR CRITERIOS DE √âXITO

**Objetivo:** Qu√© debe funcionar para aprobar la story.

### Paso 4.1: Criterios M√≠nimos

**Basados en Acceptance Criteria:**

```markdown
## ‚úÖ Criterios de √âxito

### Funcionalidad:
- [ ] AC1: [Descripci√≥n] funciona end-to-end
- [ ] AC2: [Descripci√≥n] funciona correctamente
- [ ] AC3: [Descripci√≥n] funciona sin errores

### Validaciones:
- [ ] Inputs inv√°lidos muestran mensajes claros
- [ ] Edge cases manejan correctamente
- [ ] Error handling es apropiado

### UX:
- [ ] UI es intuitiva
- [ ] Navegaci√≥n es clara
- [ ] Loading states son apropiados
- [ ] Responsive design funciona (mobile, tablet, desktop)

### Performance:
- [ ] Load times < 3 segundos
- [ ] No hay lags o freezes
- [ ] APIs responden en < 500ms (promedio)

### Calidad:
- [ ] No hay bugs cr√≠ticos (severity: critical)
- [ ] Bugs high son acceptables si hay workaround
- [ ] Bugs medium/low no bloquean aprobaci√≥n
```

---

## üîê PASO 5: PREPARAR DATOS DE PRUEBA

**Objetivo:** Asegurar que QA tiene data necesaria.

### Paso 5.1: Identificar Datos Necesarios

**Credenciales (si aplica):**
```markdown
## üìù Datos de Prueba

### Credenciales de Test:

**User normal:**
- Email: `test@example.com`
- Password: `Test123!`

**Admin:**
- Email: `admin@example.com`
- Password: `Admin123!`

**Guest:**
- Sin credenciales (testing como guest)
```

---

### Paso 5.2: Seed Data

**Si story requiere data pre-existente:**

```markdown
### Data Seeds:

**[Entidades principales]:**
- [Entity 1]: "[Nombre]" (tiene [X] relaciones activas)
- [Entity 2]: "[Nombre]" (sin relaciones)

(Donde [Entity] se determina del dominio del proyecto.
Ejemplos: Mentors en MYM, Products en SHOP, Posts en BLOG)

**[Relaciones/Transacciones]:**
- [Relation 1]: ID `xxx` (status: pending)
- [Relation 2]: ID `yyy` (status: completed)

(Ejemplos: Sessions en MYM, Orders en SHOP, Comments en BLOG)

### C√≥mo crear data de prueba:
[Instrucciones para crear data via UI o seeds]
```

---

### Paso 5.3: Test Data Edge Cases

**Data para edge cases:**

```markdown
### Test Data para Edge Cases:

**Inputs inv√°lidos a probar:**
- Email sin @: `testexample.com`
- Password muy corta: `123`
- Special characters: `<script>alert('xss')</script>`
- SQL injection: `'; DROP TABLE users; --`
- Empty fields: ` ` (solo espacios)

**Boundary values:**
- Max length: [255 chars string]
- Min value: 0, -1
- Max value: 999999
```

---

## üìÑ PASO 6: GENERAR TEST CHARTER

**Objetivo:** Documentar charter completo.

### Paso 6.1: Crear Archivo

**Acci√≥n:** Crear `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/test-charter.md`

**Contenido completo:**

```markdown
# Test Charter: [STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre} - Nombre de la Story]

**Fecha:** [Fecha actual]
**QA:** [Nombre del QA ejecutor]
**Duraci√≥n estimada:** 60-90 minutos
**Staging URL:** https://[project]-develop.vercel.app

---

## üéØ Objetivo de la Sesi√≥n

Explorar la funcionalidad [nombre de la story] en staging environment para validar:
- Acceptance criteria se cumplen completamente
- Edge cases y negative scenarios son manejados correctamente
- UX es intuitiva y no hay bugs cr√≠ticos
- Integraci√≥n con backend funciona sin errores

**Contexto:**
[Breve descripci√≥n de qu√© hace la story, por qu√© es importante]

---

## üìã √Åreas a Explorar

### 1. Happy Path - Flujo Principal (15-20 min)

**Qu√© probar:**
[Descripci√≥n del flujo principal basado en AC1, AC2, AC3]

**Steps a explorar:**
1. [Paso 1 del happy path]
2. [Paso 2 del happy path]
3. [Paso 3 del happy path]
4. [Resultado esperado]

**T√©cnica:** Feature Tour
**Tiempo:** 15-20 minutos
**Criterio de √©xito:**
- [ ] Flujo completa end-to-end sin errores
- [ ] UI refleja cambios correctamente
- [ ] Data persiste despu√©s de refrescar

---

### 2. Edge Cases & Boundary Testing (20-25 min)

**Qu√© probar:**
Validar que la aplicaci√≥n maneja correctamente:
- Inputs l√≠mite (max/min length, max/min values)
- Inputs vac√≠os
- Inputs inv√°lidos (special characters, injection attempts)

**Scenarios a explorar:**

**Formularios (si aplica):**
- [ ] Email sin @
- [ ] Password muy corta
- [ ] Campos vac√≠os
- [ ] Solo espacios en campos
- [ ] Special characters: `<script>`, `'; DROP TABLE`

**Boundary values:**
- [ ] Max length: [X chars]
- [ ] Min value: 0, -1
- [ ] Max value: [seg√∫n l√≠mite de negocio]

**T√©cnica:** Boundary Testing, Negative Testing
**Tiempo:** 20-25 minutos
**Criterio de √©xito:**
- [ ] Validaciones muestran mensajes claros
- [ ] App no crashea con inputs inv√°lidos
- [ ] Error handling es apropiado

---

### 3. UX & Usabilidad (15-20 min)

**Qu√© probar:**
Validar que la experiencia de usuario es intuitiva:
- ¬øNavegaci√≥n es clara?
- ¬øMensajes de feedback son √∫tiles?
- ¬øLoading states son apropiados?
- ¬øResponsive design funciona?

**Scenarios a explorar:**

**Navegaci√≥n:**
- [ ] Botones son claros y accesibles
- [ ] Links funcionan correctamente
- [ ] Breadcrumbs o navegaci√≥n secundaria es clara

**Feedback visual:**
- [ ] Loading spinners aparecen cuando aplica
- [ ] Success messages son claros
- [ ] Error messages son descriptivos (no solo "Error occurred")

**Responsive design:**
- [ ] Desktop (1920x1080)
- [ ] Tablet (768x1024)
- [ ] Mobile (375x667)

**T√©cnica:** UX Review, User Personas
**Tiempo:** 15-20 minutos
**Criterio de √©xito:**
- [ ] UI es intuitiva para usuario nuevo
- [ ] No hay layouts rotos en ning√∫n viewport
- [ ] Mensajes de feedback son √∫tiles

---

### 4. Integraci√≥n con Backend (15-20 min)

**Qu√© probar:**
Validar que integraci√≥n con APIs y DB funciona:
- API calls retornan correctamente
- Data persiste en DB
- Error handling de backend es apropiado

**Scenarios a explorar:**

**API Validation:**
- [ ] GET requests retornan data correcta
- [ ] POST requests crean data en DB
- [ ] PUT requests actualizan data correctamente
- [ ] DELETE requests eliminan data (si aplica)

**Data Persistence:**
- [ ] Crear data via UI ‚Üí Refrescar ‚Üí Data persiste
- [ ] Modificar data ‚Üí Refrescar ‚Üí Cambios persisten

**Error Handling:**
- [ ] Simular API down (DevTools ‚Üí Offline mode)
- [ ] App muestra mensaje de error apropiado
- [ ] App no crashea

**T√©cnica:** Data Flows, API Testing
**Tiempo:** 15-20 minutos
**Criterio de √©xito:**
- [ ] Todas las API calls retornan 200/201
- [ ] Data persiste correctamente
- [ ] Error handling es robusto

---

### 5. Performance & Responsiveness (10-15 min) - Opcional

**Qu√© probar:**
Validar que performance es aceptable:
- Load times < 3 segundos
- No hay lags o freezes
- APIs responden r√°pidamente

**Scenarios a explorar:**

**Load Times:**
- [ ] Landing page carga en < 2s
- [ ] Navegaci√≥n entre p√°ginas < 1s
- [ ] Data-heavy pages < 3s

**API Performance:**
- [ ] API calls < 500ms (promedio)
- [ ] Bulk operations < 2s

**T√©cnica:** Performance Profiling (DevTools ‚Üí Performance tab)
**Tiempo:** 10-15 minutos
**Criterio de √©xito:**
- [ ] Load times son aceptables
- [ ] No hay lags perceptibles

---

## üîç T√©cnicas a Usar Durante la Sesi√≥n

- [ ] **Tours:** Recorrer funcionalidad completa
- [ ] **Edge Cases:** Inputs l√≠mite, vac√≠os, inv√°lidos
- [ ] **Negative Testing:** Intentar romper la funcionalidad
- [ ] **Pairing:** Probar con diferentes user personas (Admin vs User)
- [ ] **UX Review:** Validar usabilidad y dise√±o
- [ ] **Data Flows:** Verificar integraci√≥n con backend

---

## ‚úÖ Criterios de √âxito General

**Para aprobar la story, debe cumplir:**

### Funcionalidad:
- [ ] AC1: [Descripci√≥n del AC1] funciona end-to-end
- [ ] AC2: [Descripci√≥n del AC2] funciona correctamente
- [ ] AC3: [Descripci√≥n del AC3] funciona sin errores

### Validaciones:
- [ ] Inputs inv√°lidos muestran mensajes claros
- [ ] Edge cases son manejados correctamente
- [ ] Error handling es apropiado y descriptivo

### UX:
- [ ] UI es intuitiva para usuario nuevo
- [ ] Navegaci√≥n es clara
- [ ] Loading states son apropiados
- [ ] Responsive design funciona (mobile, tablet, desktop)

### Performance:
- [ ] Load times < 3 segundos
- [ ] No hay lags o freezes perceptibles
- [ ] APIs responden en < 500ms (promedio)

### Calidad:
- [ ] **NO** hay bugs cr√≠ticos (bloquean funcionalidad core)
- [ ] Bugs high son aceptables si hay workaround claro
- [ ] Bugs medium/low no bloquean aprobaci√≥n

---

## üìù Datos de Prueba

### Credenciales de Test:

**User normal:**
- Email: `test@example.com`
- Password: `Test123!`

**Admin:**
- Email: `admin@example.com`
- Password: `Admin123!`

**Guest:**
- Testing sin autenticaci√≥n (si aplica)

---

### Seed Data (si aplica):

[Describir data pre-existente necesaria o c√≥mo crearla]

**Ejemplo:**
(Analizar la story para identificar qu√© entidades de negocio usar)

- [Entity 1]: "[Nombre]" (tiene [X] relaciones activas)
- [Relation 1]: ID `xxx` (status: [estado])

(Donde [Entity/Relation] depende del dominio. Ejemplos: Mentor/Session en MYM, Product/Order en SHOP, Post/Comment en BLOG)

---

### Test Data para Edge Cases:

**Inputs inv√°lidos a probar:**
- Email sin @: `testexample.com`
- Password muy corta: `123`
- Special characters: `<script>alert('xss')</script>`
- SQL injection: `'; DROP TABLE users; --`
- Empty fields: ` ` (solo espacios)

**Boundary values:**
- Max length: [255 chars string]
- Min value: 0, -1
- Max value: [seg√∫n l√≠mites de negocio]

---

## üêõ Reportar Bugs

**Si encuentras bugs durante la sesi√≥n:**

1. Documentar en session notes (session-notes.md)
2. Crear bug report estructurado (bug-report.md)
3. Severidad:
   - **Critical:** Bloquea funcionalidad core, no hay workaround
   - **High:** Funcionalidad parcial, workaround dif√≠cil
   - **Medium:** Issue de UX, hay workaround f√°cil
   - **Low:** Mejora cosm√©tica

---

## üìä M√©tricas a Capturar

**Durante la sesi√≥n, capturar:**
- Tiempo real invertido por √°rea
- N√∫mero de bugs encontrados (por severidad)
- % de charter completado
- Decisi√≥n final: PASSED / PASSED WITH ISSUES / FAILED

---

## üí° Tips para la Sesi√≥n

1. **Time-box estrictamente:** No invertir m√°s del tiempo asignado por √°rea
2. **Documentar mientras exploras:** No esperar al final
3. **Screenshots de bugs:** Capturar evidencia inmediatamente
4. **Revisar console/network:** Siempre tener DevTools abierto
5. **Si encuentras bug cr√≠tico:** STOP, reportar inmediatamente

---

## üîó Referencias

**Documentos relacionados:**
- Story: `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/story.md`
- Test Cases: `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/test-cases.md`
- Smoke Test: `.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/smoke-test.md`

**Pr√≥ximos pasos:**
- Ejecutar sesi√≥n ‚Üí Documentar en session-notes.md
- Reportar bugs ‚Üí bug-report.md

---

**üéØ Charter ready para ejecutar!**
```

---

## üéâ REPORTE FINAL

**Mostrar al usuario:**

```markdown
# ‚úÖ TEST CHARTER GENERADO

## Archivo Creado:

`.context/PBI/epics/EPIC-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/stories/STORY-{PROJECT_KEY}-{ISSUE_NUM}-{nombre}/test-charter.md`

---

## üìä Charter Summary:

**√Åreas de exploraci√≥n:** [X] √°reas
**Duraci√≥n estimada:** 60-90 minutos
**T√©cnicas incluidas:** Tours, Edge Cases, UX Review, Backend Integration

**Distribuci√≥n de tiempo:**
- √Årea 1 (Happy Path): 15-20 min
- √Årea 2 (Edge Cases): 20-25 min
- √Årea 3 (UX): 15-20 min
- √Årea 4 (Backend): 15-20 min
- Buffer: 10 min

---

## Pr√≥ximos Pasos:

### 1Ô∏è‚É£ Ejecutar Sesi√≥n Exploratoria

Usa el charter creado para guiar la sesi√≥n:

**Duraci√≥n:** 60-90 minutos
**Staging URL:** https://[project]-develop.vercel.app

**Documentar hallazgos:**
```bash
Use: .prompts/fase-10-exploratory-testing/session-notes.md
```

---

### 2Ô∏è‚É£ Reportar Bugs Encontrados

Si encuentras bugs durante la sesi√≥n:

```bash
Use: .prompts/fase-10-exploratory-testing/bug-report.md
```

---

### 3Ô∏è‚É£ Despu√©s de la Sesi√≥n

**Si PASSED:**
- Continuar a Fase 11 (Test Automation)
- Automatizar test cases cr√≠ticos

**Si FAILED:**
- Development fix bugs
- Re-deploy a staging
- Re-ejecutar exploratory testing

---

**üéä Charter ready para ejecutar!**
```

---

## üìã CHECKLIST INTERNO (NO MOSTRAR)

**Validaciones antes de finalizar:**

### Story Analizada:
- [ ] Acceptance criteria completos le√≠dos
- [ ] Test cases de Fase 5 revisados
- [ ] √Åreas de riesgo identificadas

### Charter Completo:
- [ ] Objetivo de sesi√≥n claro
- [ ] 3-5 √°reas de exploraci√≥n definidas
- [ ] Time-boxing por √°rea incluido
- [ ] T√©cnicas espec√≠ficas asignadas
- [ ] Criterios de √©xito definidos
- [ ] Datos de prueba incluidos

### Documentaci√≥n:
- [ ] Archivo creado en ruta correcta
- [ ] Staging URL incluida
- [ ] Referencias a docs relacionados
- [ ] Pr√≥ximos pasos claros

---

## üí° MEJORES PR√ÅCTICAS

### **1. Time-box Estrictamente**

**60-90 minutos distribuidos:**
```
Happy Path:          20% del tiempo (12-18 min)
Edge Cases:          35% del tiempo (21-32 min)
UX:                  25% del tiempo (15-23 min)
Backend Integration: 15% del tiempo (9-14 min)
Buffer:              5% del tiempo (3-5 min)
```

**Por qu√©:** Evita over-testing en una √°rea y sub-testing en otras.

---

### **2. Basarse en Test Cases de Fase 5**

**Test cases ya definen:**
- Happy path scenarios
- Edge cases
- Negative scenarios

**Charter debe expandir test cases:**
- Test cases ‚Üí Qu√© testear
- Charter ‚Üí C√≥mo explorar + t√©cnicas + time-boxing

---

### **3. Incluir Diferentes T√©cnicas**

**No usar solo una t√©cnica:**
- ‚ùå Solo happy path testing
- ‚úÖ Tours + Edge cases + UX review + Negative testing

**Beneficio:** Encuentra m√°s bugs, mejor cobertura.

---

### **4. Criterios de √âxito ‚â† Perfecci√≥n**

**Criterios realistas:**
- ‚úÖ NO bugs cr√≠ticos
- ‚úÖ Bugs high aceptables si hay workaround
- ‚úÖ Bugs medium/low no bloquean

**No esperar:**
- ‚ùå Zero bugs
- ‚ùå UX perfecta
- ‚ùå Performance √≥ptima

**Por qu√©:** Balance entre calidad y shipping velocity.

---

### **5. Preparar Datos de Prueba ANTES**

**NO improvisar durante sesi√≥n:**
- ‚ùå "No s√© qu√© credenciales usar"
- ‚ùå "No hay data de prueba"

**Incluir en charter:**
- ‚úÖ Credenciales de test
- ‚úÖ Seed data necesaria
- ‚úÖ Test data para edge cases

**Beneficio:** Sesi√≥n es m√°s eficiente.

---

## üìö REFERENCIAS

**Exploratory testing techniques:**
- https://www.ministryoftesting.com/dojo/lessons/session-based-test-management

**Test charter best practices:**
- https://www.satisfice.com/download/session-based-test-management

**Guidelines:**
- `.context/guidelines/exploratory-testing.md`
- `.context/guidelines/testing-strategy.md`

---

**‚úÖ Test Charter = Gu√≠a estructurada (60-90 min) + Time-boxing + T√©cnicas espec√≠ficas + Criterios de √©xito claros**
