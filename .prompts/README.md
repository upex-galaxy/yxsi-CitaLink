# ğŸ¤– AI PROMPTS - Context Engineering para Desarrollo de Software

Este directorio contiene prompts optimizados para generar documentaciÃ³n de proyecto siguiendo el **AI-Driven Software Project Blueprint**.

---

## ğŸ“‹ ÃNDICE DE PROMPTS

### **ğŸ”¹ FASES SINCRÃ“NICAS** (una sola vez, setup inicial)

#### **Fase 1: Constitution** (DefiniciÃ³n del modelo de negocio)
- `fase-1-constitution/business-model.md` - Generar Business Model Canvas
- `fase-1-constitution/market-context.md` - Generar anÃ¡lisis de mercado

#### **Fase 2: Architecture** (Product + Technical specs)

**PRD (Product Requirements Document):**
- `fase-2-architecture/prd-executive-summary.md` - Problem statement, solution, KPIs
- `fase-2-architecture/prd-user-personas.md` - Perfiles de usuarios objetivo
- `fase-2-architecture/prd-mvp-scope.md` - Ã‰picas iniciales y user stories del MVP
- `fase-2-architecture/prd-user-journeys.md` - Flujos de usuario (happy + edge cases)

**SRS (Software Requirements Specification):**
- `fase-2-architecture/srs-functional-specs.md` - Requerimientos funcionales
- `fase-2-architecture/srs-non-functional-specs.md` - Performance, security, scalability
- `fase-2-architecture/srs-architecture-specs.md` - Arquitectura del sistema
- `fase-2-architecture/srs-api-contracts.md` - OpenAPI spec de endpoints

---

### **ğŸ”¹ FASES ASINCRÃ“NICAS** (iterativas, por sprint/Ã©pica)

#### **Fase 3: Specification** (Product Backlog)
- `fase-3-specification/pbi-product-backlog.md` - Crear epic-tree, Ã©picas y stories

#### **Fase 4: Shift-Left Testing** (QA temprano)
- `fase-4-shift-left-testing/feature-test-plan.md` - Plan de pruebas a nivel Ã©pica
- `fase-4-shift-left-testing/story-test-cases.md` - Test cases detallados por story

#### **Fase 5: Planning** (PlanificaciÃ³n tÃ©cnica)
- `fase-5-planning/feature-implementation-plan.md` - Plan tÃ©cnico a nivel Ã©pica
- `fase-5-planning/story-implementation-plan.md` - Plan detallado de implementaciÃ³n por story

#### **Fase 6: Implementation** âŒ NO HAY PROMPTS
**Â¿Por quÃ© no hay prompts?**
- Esta fase usa `.context/guidelines/` como referencia (no genera docs)
- La IA implementa cÃ³digo siguiendo los implementation plans de Fase 5
- Lee: `.context/guidelines/implementation-workflow.md`, `code-standards.md`, etc.

#### **Fase 7: Code Review** âŒ NO HAY PROMPTS
**Â¿Por quÃ© no hay prompts?**
- Esta fase usa `.context/guidelines/code-standards.md` como referencia
- El reviewer verifica adherencia a estÃ¡ndares de cÃ³digo
- NO genera documentaciÃ³n adicional

#### **Fase 8: Test Automation Engineering** (Arquitectura de testing)
- `fase-8-test-automation/test-strategy.md` - Estrategia general de testing del proyecto
- `fase-8-test-automation/kata-implementation-plan.md` - Plan de implementaciÃ³n de KATA framework
- `fase-8-test-automation/automation-standards.md` - EstÃ¡ndares de cÃ³digo para tests

---

## ğŸ¯ CÃ“MO USAR ESTOS PROMPTS

### **Instrucciones Generales**

1. **Abrir el archivo del prompt** correspondiente a la fase en la que estÃ¡s
2. **Copiar TODO el contenido** del archivo (Ctrl+A â†’ Ctrl+C)
3. **Pegar en tu chat con la IA** (Claude, ChatGPT, etc.)
4. **Reemplazar los placeholders** con tu informaciÃ³n especÃ­fica:
   - `[usar archivo.md]` â†’ Pega el contenido del archivo referenciado
   - `[industria/vertical]` â†’ Especifica tu industria
   - `[proyecto]` â†’ Nombre de tu proyecto
5. **Ejecutar el prompt**
6. **Copiar la respuesta de la IA** al archivo destino en `.context/`

---

### **Workflow Secuencial**

#### **ğŸ”¹ FASES SINCRÃ“NICAS** (una sola vez)

#### **Paso 1: Fase 1 - Constitution**

1. Usa `business-model.md` â†’ Genera `.context/idea/business-model.md`
2. Usa `market-context.md` (pega el business-model.md previo) â†’ Genera `.context/idea/market-context.md`

#### **Paso 2: Fase 2 - Architecture (PRD)**

1. Usa `prd-executive-summary.md` â†’ Genera `.context/PRD/executive-summary.md`
2. Usa `prd-user-personas.md` â†’ Genera `.context/PRD/user-personas.md`
3. Usa `prd-mvp-scope.md` â†’ Genera `.context/PRD/mvp-scope.md`
4. Usa `prd-user-journeys.md` â†’ Genera `.context/PRD/user-journeys.md`

#### **Paso 3: Fase 2 - Architecture (SRS)**

1. Usa `srs-functional-specs.md` â†’ Genera `.context/SRS/functional-specs.md`
2. Usa `srs-non-functional-specs.md` â†’ Genera `.context/SRS/non-functional-specs.md`
3. Usa `srs-architecture-specs.md` â†’ Genera `.context/SRS/architecture-specs.md`
4. Usa `srs-api-contracts.md` â†’ Genera `.context/SRS/api-contracts.yaml`

---

#### **ğŸ”¹ FASES ASINCRÃ“NICAS** (iterativas, por sprint/Ã©pica)

#### **Paso 4: Fase 3 - Specification (PBI)**

1. Usa `pbi-product-backlog.md` â†’ Genera:
   - `.context/PBI/epic-tree.md`
   - `.context/PBI/epics/EPIC-XXX/epic.md` (por cada Ã©pica)
   - `.context/PBI/epics/EPIC-XXX/stories/STORY-XXX/story.md` (por cada story)

#### **Paso 5: Fase 4 - Shift-Left Testing (por cada Ã©pica)**

1. Usa `feature-test-plan.md` â†’ Genera `.context/PBI/epics/EPIC-XXX/feature-test-plan.md`

**Por cada story de la Ã©pica:**
2. Usa `story-test-cases.md` â†’ Genera `.context/PBI/epics/EPIC-XXX/stories/STORY-XXX/test-cases.md`

#### **Paso 6: Fase 5 - Planning (por cada Ã©pica)**

1. Usa `feature-implementation-plan.md` â†’ Genera `.context/PBI/epics/EPIC-XXX/feature-implementation-plan.md`

**Por cada story de la Ã©pica:**
2. Usa `story-implementation-plan.md` â†’ Genera `.context/PBI/epics/EPIC-XXX/stories/STORY-XXX/implementation-plan.md`

#### **Paso 7: Fase 6 - Implementation**

âŒ **NO hay prompts para esta fase**

La IA implementa cÃ³digo siguiendo:
- `.context/PBI/epics/EPIC-XXX/stories/STORY-XXX/implementation-plan.md` (de Fase 5)
- `.context/guidelines/implementation-workflow.md`
- `.context/guidelines/code-standards.md`
- `.context/guidelines/error-handling.md`
- `.context/guidelines/mcp-usage-tips.md`

#### **Paso 8: Fase 7 - Code Review**

âŒ **NO hay prompts para esta fase**

El reviewer verifica:
- Adherencia a `.context/guidelines/code-standards.md`
- Tests completos
- Documentation actualizada

#### **Paso 9: Fase 8 - Test Automation Engineering (TAE)**

**Una sola vez para todo el proyecto:**

1. Usa `test-strategy.md` â†’ Genera `.context/guidelines/tae/test-strategy.md`
   - Input: PRD completo, SRS completo, PBI epic-tree
   - Define estrategia de testing: scope, niveles, componentes KATA, execution strategy

2. Usa `kata-implementation-plan.md` â†’ Genera `.context/guidelines/tae/kata-implementation-plan.md`
   - Input: Test Strategy, PBI completo, SRS Architecture
   - Define roadmap de implementaciÃ³n: componentes API/UI, ATCs por componente, priorizaciÃ³n

3. Usa `automation-standards.md` â†’ Genera `.context/guidelines/tae/automation-standards.md`
   - Input: Test Strategy, KATA Architecture docs
   - Define estÃ¡ndares: naming conventions, code structure, assertions guidelines, code review checklist

**Archivos de referencia (ya completos en `.context/guidelines/tae/`):**
- `kata-architecture.md` - DocumentaciÃ³n completa de KATA adaptada al proyecto
- `test-data-management.md` - Estrategias de gestiÃ³n de datos de prueba
- `tms-integration.md` - IntegraciÃ³n con Xray Cloud o Jira Direct
- `ci-cd-integration.md` - ConfiguraciÃ³n de GitHub Actions para tests

**Plantillas (llenar conforme se implementa):**
- `component-catalog.md` - CatÃ¡logo de componentes implementados
- `atc-registry.md` - Registro de ATCs con trazabilidad a Jira

---

## âš™ï¸ TIPS DE USO

### **Contexto Acumulativo**

Los prompts estÃ¡n diseÃ±ados para funcionar en cascada:
- Cada prompt pide como input el output de prompts anteriores
- Siempre pega el contenido de los archivos generados previamente cuando el prompt lo solicite

### **Placeholders a Reemplazar**

Cuando veas:
- `[usar archivo.md]` â†’ Copia y pega el contenido completo del archivo
- `[especificar X]` â†’ Reemplaza con tu valor especÃ­fico
- `[listar Y]` â†’ Lista los elementos solicitados

### **IteraciÃ³n**

- Si la IA genera algo que no te gusta, puedes pedirle que lo refine
- Puedes agregar contexto adicional entre corchetes en el prompt
- Los prompts son templates, no reglas absolutas

### **Herramientas Complementarias**

- **Supabase MCP:** Para obtener schema real de DB (no usar SQL estÃ¡tico en docs)
- **Atlassian MCP:** Para sincronizar PBI con Jira despuÃ©s de generarlos
- **Mermaid Live Editor:** Para visualizar/editar diagramas generados

---

## ğŸš¨ IMPORTANTE

### **NO hacer:**
- âŒ Modificar los prompts sin entender su propÃ³sito
- âŒ Saltarse fases (cada fase depende de la anterior)
- âŒ Usar SQL estÃ¡tico en documentaciÃ³n (siempre usar Supabase MCP)

### **SÃ hacer:**
- âœ… Seguir el orden secuencial de fases
- âœ… Pegar contexto completo cuando el prompt lo solicite
- âœ… Revisar y refinar outputs de la IA
- âœ… Mantener consistencia en naming (IDs de Ã©picas/stories)

---

## ğŸ“ ESTRUCTURA DE SALIDA ESPERADA

DespuÃ©s de usar todos los prompts, tu directorio `.context/` debe verse asÃ­:

```
.context/
â”œâ”€â”€ idea/                          [Fase 1]
â”‚   â”œâ”€â”€ business-model.md
â”‚   â””â”€â”€ market-context.md
â”‚
â”œâ”€â”€ PRD/                           [Fase 2]
â”‚   â”œâ”€â”€ executive-summary.md
â”‚   â”œâ”€â”€ user-personas.md
â”‚   â”œâ”€â”€ mvp-scope.md
â”‚   â””â”€â”€ user-journeys.md
â”‚
â”œâ”€â”€ SRS/                           [Fase 2]
â”‚   â”œâ”€â”€ functional-specs.md
â”‚   â”œâ”€â”€ non-functional-specs.md
â”‚   â”œâ”€â”€ architecture-specs.md
â”‚   â””â”€â”€ api-contracts.yaml
â”‚
â”œâ”€â”€ PBI/                           [Fases 3-5]
â”‚   â”œâ”€â”€ epic-tree.md
â”‚   â””â”€â”€ epics/
â”‚       â””â”€â”€ EPIC-XXX-nombre/
â”‚           â”œâ”€â”€ epic.md                     [Fase 3]
â”‚           â”œâ”€â”€ feature-test-plan.md        [Fase 4]
â”‚           â”œâ”€â”€ feature-implementation-plan.md [Fase 5]
â”‚           â””â”€â”€ stories/
â”‚               â””â”€â”€ STORY-XXX-nombre/
â”‚                   â”œâ”€â”€ story.md            [Fase 3]
â”‚                   â”œâ”€â”€ test-cases.md       [Fase 4]
â”‚                   â””â”€â”€ implementation-plan.md [Fase 5]
â”‚
â””â”€â”€ guidelines/                    [Fases 6-7-8 - Reference material]
    â”œâ”€â”€ implementation-workflow.md
    â”œâ”€â”€ code-standards.md
    â”œâ”€â”€ error-handling.md
    â”œâ”€â”€ context-loading.md
    â”œâ”€â”€ mcp-usage-tips.md
    â”‚
    â””â”€â”€ tae/                       [Fase 8]
        â”œâ”€â”€ README.md
        â”œâ”€â”€ test-strategy.md
        â”œâ”€â”€ kata-architecture.md
        â”œâ”€â”€ kata-implementation-plan.md
        â”œâ”€â”€ component-catalog.md
        â”œâ”€â”€ atc-registry.md
        â”œâ”€â”€ automation-standards.md
        â”œâ”€â”€ test-data-management.md
        â”œâ”€â”€ tms-integration.md
        â””â”€â”€ ci-cd-integration.md
```

---

## ğŸ”— RECURSOS ADICIONALES

- **Blueprint completo:** `docs/ai-driven-software-project-blueprint.md`
- **KATA Architecture (TAE):** `docs/kata-test-architecture.md`
- **Guidelines para IA:** `.context/guidelines/`

---

## ğŸ“ SOPORTE

Si tienes dudas sobre cÃ³mo usar estos prompts:
1. Lee el Blueprint completo en `docs/`
2. Consulta los ejemplos en cada prompt
3. Experimenta con prompts individuales primero

---

**VersiÃ³n:** 3.0 (8 Fases: SincrÃ³nicas + AsincrÃ³nicas)
**Ãšltima actualizaciÃ³n:** 2025-10-29
**Autor:** UPEX Galaxy - DOJO AI-Powered Quality Engineer
